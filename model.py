from __future__ import division
#python scripts
__author__='Du Jiawei'
#Descrption:
from keras import backend as K
K.set_image_dim_ordering('tf')
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.models import load_model
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers.convolutional import Convolution2D, MaxPooling2D,ZeroPadding2D,AveragePooling2D
from keras.layers.convolutional import Convolution1D, MaxPooling1D,ZeroPadding1D,AveragePooling1D
from keras.layers.normalization import BatchNormalization
from keras.optimizers import SGD, RMSprop

from keras.utils import np_utils, generic_utils


import xgboost as xgb
import pandas as pd
import math
import matplotlib
import csv
import numpy as np
import getdata
import os.path as osp
matplotlib.use('agg')
import pickle
from sklearn.metrics import accuracy_score

input_size = 1024
# input_size = 4096
model_save = "data/malware_xgb.dat"
def getModel(load_model=None):

    model = Sequential()

    model.add(Convolution1D(3,(3),padding='valid',input_shape=(input_size,1)))
    model.add(BatchNormalization())
    model.add(Activation('relu'))


    model.add(Convolution1D(3,(3),padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))

    model.add(MaxPooling1D(pool_size=(2)))

    model.add(Convolution1D(6,(3),padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))


    model.add(Convolution1D(6,(3),padding='valid'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))

    model.add(MaxPooling1D(pool_size=(2)))

    # model.add(Convolution1D(12,(3),padding='valid'))
    # model.add(BatchNormalization())
    # model.add(Activation('relu'))


    # model.add(Convolution1D(12,(3),padding='valid'))
    # model.add(BatchNormalization())
    # model.add(Activation('relu'))

    # model.add(MaxPooling1D(pool_size=(2)))


    model.add(Flatten())
    # model.add(Dense(64,activation="relu"))
    # model.add(Dropout(0.5))
    model.add(Dense(16,activation="relu"))
    model.add(Dropout(0.5))
    model.add(Dense(16,activation="relu"))
    model.add(Dense(2,activation="softmax"))


    print model.summary()
    if load_model!=None:
        model.load_weights(load_model)
        print "model of {} loaded".format(load_model)

    return model


def main():
    load_model = False
    model_save =  "data/xgb.dat"

    (x,y),(x_t, y_t) = getdata.get_data(size=1000000,test_size=0.05)
    print "x shape is ",x.shape
    # x=x.reshape((-1,input_size,1))
    # x_t=x_t.reshape((-1,input_size,1))

    # print "data loaded"
    # model = getModel()
    # model.compile(loss="binary_crossentropy",optimizer="Adam",metrics=['accuracy'])

    # model.fit(x=x,y=y,batch_size=128,epochs=40,validation_data=(x_t,y_t))
    # print "model training finished and saved"


    train_ratio = y.shape[0]/np.sum(y)-1
    if osp.isfile(model_save) and load_model:
        clf =pickle.load(open(model_save,"rb"))
    else:

        clf = xgb.XGBRegressor(max_depth=10,
                n_estimators=1500,
                min_child_weight=9,
                learning_rate=0.05,
                nthread=8,
                subsample=0.80,
                colsample_bytree=0.80,
                seed=4242,
                scale_pos_weight=train_ratio)
        clf.fit(x,y)
        pickle.dump(clf, open(model_save, "wb"))
    model = clf
    
    print "acry is ",test_accuracy(model,x_t,y_t)
def save_csv(inp):
    save_file = pd.DataFrame(inp)
    save_file.to_csv("result.csv",header=False,index=True)
def test_result():

    clf =pickle.load(open(model_save,"rb"))


    train_label_path = "/data/home/dujw/weitao/data/train_label.csv"
    train_path = "/data/home/dujw/weitao/data/train.csv"
    test_path = "/data/home/dujw/weitao/data/test.csv"
    result = []
    count_point = 0
    with open(test_path, "rb") as csvfile:
    # with open(train_path, "rb") as csvfile:
        datareader = csv.reader(csvfile)
        for row in datareader:
            row = np.array(row)
            # if row.shape[0]<=1024:
                # zeros = np.zeros(1024)
                # zeros[:row.shape[0]] = row
                # row = zeros.reshape(-1,1024)
                # y_r = clf.predict(row)
                # result.append(np.sign(y_r-0.5))

            split_number = math.ceil(row.shape[0]/1024)
            split_number = int(split_number)
            zeros = np.zeros(split_number*1024)
            zeros[:row.shape[0]] = row
            row = zeros.reshape(-1,1024)
            y_r = clf.predict(row)
            y_r = np.max(y_r)
            if y_r > 0.5:
                y_r = 1 
            else:
                y_r = 0 
            result.append(y_r)

            count_point += 1
            if count_point >= 1000000:
                break
        y_pred = np.array(result)
        save_csv(y_pred)
        # y_t = getdata.label('data/train_label.csv', 10000)
        # y_t = np.argmax(y_t,axis = 1)
        # print "acry is ",accuracy_score(y_t,y_pred)



def test_accuracy(clf,x,y):
    threh = 0.5
    y_pred = clf.predict(x)
    y_pred[y_pred>threh] = 1
    y_pred[y_pred<threh] = 0
    acry = accuracy_score(y,y_pred)
    return acry
if __name__ == '__main__':
    # main()
    test_result()
